# hprof-slurp

`hprof-slurp` is a CLI analyzing JVM heap dumps using the binary `hprof` format.

The main goal is to enable the analysis of huge heap dumps which are much bigger than the amount of RAM available on the host system. 

## Features

- displays top `n` allocated classes.
- displays number of instances per class.
- displays largest instance size per class.
- list all Strings found.
- low memory usage.
- easy to use.

## Limitations

- Tested only with `JAVA PROFILE 1.0.2` & `JAVA PROFILE 1.0.1` formats.
- Does not support dumps generated by 32 bits JVM.

## Usage

```
./hprof-slurp --help
hprof-slurp 0.1.0
Arnaud Gourlay <arnaud.gourlay@gmail.com>
JVM heap dump hprof file analyzer

USAGE:
    hprof-slurp [FLAGS] [OPTIONS] --inputFile <inputFile>

FLAGS:
    -d, --debug          debug info
    -h, --help           Prints help information
    -l, --listStrings    list all Strings found
    -V, --version        Prints version information

OPTIONS:
    -i, --inputFile <inputFile>    binary hprof input file
    -t, --top <top>                the top results to display [default: 20]
```

Example:

```
./hprof-slurp -i "test-heap-dumps/hprof-64.bin"
```

```
Top 20 allocations for the 2.49MiB heap total size:

Total size | Instances |     Largest | Class name
----------------------------------------------------------------------------------
   1.99MiB |       436 |   634.77KiB | Int[]
 189.33KiB |      1991 |    16.00KiB | Char[]
  83.52KiB |       443 |     8.00KiB | Byte[]
  45.42KiB |       560 |     8.02KiB | java/lang/Object[]
  41.45KiB |      1516 |  28.00bytes | java/lang/String
  14.77KiB |       378 |  40.00bytes | java/util/LinkedList$Node
  13.90KiB |       126 | 113.00bytes | java/lang/reflect/Field
   9.11KiB |       212 |  44.00bytes | java/util/HashMap$Node
   7.42KiB |       190 |  40.00bytes | java/util/LinkedList
   5.91KiB |        18 |     2.02KiB | java/util/HashMap$Node[]
   5.36KiB |        98 |  56.00bytes | java/lang/ref/SoftReference
   5.04KiB |       258 |  20.00bytes | java/lang/Integer
   4.98KiB |       116 |  44.00bytes | java/util/Hashtable$Entry
   4.10KiB |       150 |  28.00bytes | java/lang/StringBuilder
   3.50KiB |        32 | 112.00bytes | java/net/URL
   3.17KiB |        12 | 776.00bytes | java/util/Hashtable$Entry[]
   3.14KiB |        73 |  44.00bytes | java/io/File
   3.13KiB |        56 | 144.00bytes | java/lang/String[]
   2.71KiB |        63 |  44.00bytes | java/util/concurrent/ConcurrentHashMap$Node
   2.50KiB |        40 |  64.00bytes | java/lang/ref/Finalizer
```

## Installation

Build the project using [Cargo](https://doc.rust-lang.org/stable/cargo/getting-started/installation.html)

Then run the following command in the project directory:

`cargo install --path=.`

## How it works

The binary file is parsed in a streaming fashion and only the necessary information is extracted for analysis.

The `hprof` specification used can be found [here](https://hg.openjdk.java.net/jdk/jdk/file/ee1d592a9f53/src/hotspot/share/services/heapDumper.cpp#l62).

## HPROF

`hprof` files are sometimes generated in case of a JVM crash depending on your runtime configuration.

It can also be done manually by triggering a heap dump using `jmap`.

Example:

`jmap -dump:format=b,file=my-hprof-file.bin <pid>`

## Prior art of HPROF parsing

Several projects have been very useful while researching and implementing this tool.
They have provided guidance and inspiration in moments of uncertainty.

- https://github.com/monoid/hprof_dump_parser
- https://github.com/eaftan/hprof-parser

## TODO

- use stacktrace/frame dump to compute allocation sites
